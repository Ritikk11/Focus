accelerate launch \
  --mixed_precision bf16 \
  --num_cpu_threads_per_process 1 \
  sd-scripts/flux_train_network.py \
  --pretrained_model_name_or_path "/content/fluxgym-Colab/models/unet/flux1-dev-fp8.safetensors" \
  --clip_l "/content/fluxgym-Colab/models/clip/clip_l.safetensors" \
  --t5xxl "/content/fluxgym-Colab/models/clip/t5xxl_fp8.safetensors" \
  --ae "/content/fluxgym-Colab/models/vae/ae.sft" \
  --cache_latents_to_disk \
  --save_model_as safetensors \
  --sdpa --persistent_data_loader_workers \
  --max_data_loader_n_workers 2 \
  --seed 42 \
  --gradient_checkpointing \
  --mixed_precision bf16 \
  --save_precision bf16 \
  --network_module networks.lora_flux \
  --network_dim 4 \
  --optimizer_type adafactor \
  --optimizer_args "relative_step=False" "scale_parameter=False" "warmup_init=False" \
  --split_mode \
  --network_args "train_blocks=single" \
  --lr_scheduler constant_with_warmup \
  --max_grad_norm 0.0 \
  --learning_rate 8e-4 \
  --cache_text_encoder_outputs \
  --cache_text_encoder_outputs_to_disk \
  --fp8_base \
  --max_train_epochs 16 \
  --save_every_n_epochs 4 \
  --dataset_config "/content/fluxgym-Colab/dataset.toml" \
  --output_dir "/content/fluxgym-Colab/outputs" \
  --output_name anaya \
  --timestep_sampling shift \
  --discrete_flow_shift 3.1582 \
  --model_prediction_type raw \
  --guidance_scale 1 \
  --loss_type l2 \
  --blocks_to_swap 16